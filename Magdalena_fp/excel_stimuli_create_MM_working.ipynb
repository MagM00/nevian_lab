{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b49a6be-0256-4268-b525-8dc65f2f3854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tkinter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from data_import import import_ppd\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.stats import sem\n",
    "from scipy.ndimage import gaussian_filter1d, uniform_filter1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d951cac-a6b2-42e4-bf50-508d03a95044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ppd(ppd_file_path, first_frame):\n",
    "    # Extract the filename without the extension\n",
    "    filename = os.path.splitext(os.path.basename(ppd_file_path))[0]\n",
    "\n",
    "    # Load the data from the PPD file\n",
    "    data = import_ppd(ppd_file_path, low_pass=20, high_pass=0.001)\n",
    "\n",
    "    sampling_rate=100\n",
    "\n",
    "    # Convert sample index to time vector\n",
    "    time = np.arange(len(data['analog_1'])) / sampling_rate\n",
    "\n",
    "    # dFF using 405 fit as baseline\n",
    "    reg = np.polyfit(data['analog_2'], data['analog_1'], 1)  # ch1 is 465nm, ch2 is 405nm\n",
    "    fit_405 = reg[0] * data['analog_2'] + reg[1]\n",
    "    dFF = (data['analog_1'] - fit_405) / fit_405  # deltaF/F\n",
    "    dFF = gaussian_filter1d(dFF, sigma=2)\n",
    "\n",
    "    data['fit_405'] = fit_405\n",
    "    data['dFF'] = dFF\n",
    "\n",
    "    \"\"\"     # Create the figure and subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    # Plot 1\n",
    "    ax1.plot(time, data['analog_1'], label='analog_1')\n",
    "    ax1.plot(time, data['analog_2'], label='analog_2')\n",
    "    ax1.plot(time, data['fit_405'], label='fit_405')\n",
    "\n",
    "    # Set plot 1 properties\n",
    "    ax1.set_xlabel('Time')\n",
    "    ax1.set_ylabel('Value')\n",
    "    ax1.set_title('Plot 1')\n",
    "    ax1.legend()\n",
    "\n",
    "    # Plot 2\n",
    "    ax2.plot(time, data['dFF'], label='dFF')\n",
    "\n",
    "    # Set plot 2 properties\n",
    "    ax2.set_xlabel('Time')\n",
    "    ax2.set_ylabel('Value')\n",
    "    ax2.set_title('Plot 2')\n",
    "    ax2.legend()\n",
    "\n",
    "    # Adjust spacing between subplots\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Set the figure title\n",
    "    fig.suptitle(filename)\n",
    "\n",
    "    # Save the figure as PNG with 300 dpi\n",
    "    save_path = os.path.join(os.path.dirname(ppd_file_path), filename + '.png')\n",
    "    fig.savefig(save_path, dpi=300)\n",
    "\n",
    "    # Display the plots\n",
    "    plt.show() \"\"\"\n",
    "\n",
    "    # Index of np.diff(data['digital_1']) bigger than 0.5 or smaller than -0.5\n",
    "    index_on = np.where(np.diff(data['digital_1']) > 0.5)[0]\n",
    "    index_off = np.where(np.diff(data['digital_1']) < -0.5)[0]\n",
    "\n",
    "    ttl_duration = index_off - index_on\n",
    "\n",
    "\n",
    "\n",
    "    # Remove indexes with ttl_duration < 20\n",
    "    indexes_to_remove = np.where(ttl_duration < 0)[0] #\n",
    "    index_on_new = np.delete(index_on, indexes_to_remove)\n",
    "    index_off_new = np.delete(index_off, indexes_to_remove)\n",
    "    ttl_duration_new = np.delete(ttl_duration, indexes_to_remove)\n",
    "\n",
    "    time_on_new = index_on_new / sampling_rate\n",
    "    frame_on_new = np.round((index_on_new) / sampling_rate * 30) + first_frame - np.round((index_on_new[0]) / sampling_rate * 30)\n",
    "\n",
    "\n",
    "    \"\"\" \n",
    "        # Organize data into a dictionary\n",
    "    data = {\n",
    "        'mouse': {\n",
    "            'Stim': [\n",
    "                1,1,1,3,3,3,2,2,2,0,0,0,5,5,5,6,6,6,4,4,4,\n",
    "                6,6,6,2,2,2,3,3,3,4,4,4,5,5,5,1,1,1,0,0,0,\n",
    "                4,4,4,1,1,1,2,2,2,5,5,5,3,3,3,6,6,6,0,0,0,\n",
    "                6,6,6,0,0,0,5,5,5,1,1,1,2,2,2,4,4,4,3,3,3,\n",
    "                4,4,4,6,6,6,1,1,1,5,5,5,0,0,0,2,2,2,3,3,3\n",
    "            ],\n",
    "            'Time': time_on_new.tolist()\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Organize data into a dictionary\n",
    "    data = {\n",
    "        'mouse': {\n",
    "            'Stim': [\n",
    "                1,1,1,3,3,3,2,2,2,0,0,0,5,5,5,6,6,6,4,4,4,\n",
    "                6,6,6,2,2,2,3,3,3,4,4,4,5,5,5,1,1,1,0,0,0,\n",
    "                4,4,4,1,1,1,2,2,2,5,5,5,3,3,3,6,6,6,0,0,0,\n",
    "                6,6,6,0,0,0,5,5,5,1,1,1,2,2,2,4, 4,4,3,3,3,\n",
    "                4,4,4,6,6,6,1,1,1,5,5,5,0,0,0,2,2,2,3,3,3\n",
    "            ],\n",
    "            'Time': time_on_new.tolist()\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Use `data` as needed in your analysis\n",
    "\n",
    "    stim_data = data['mouse']['Stim']\n",
    "    time_stamps = data['mouse']['Time']\n",
    "\n",
    "    pinp_indexes = [i for i, stim in enumerate(stim_data) if stim == 0]\n",
    "    weak_indexes = [i for i, stim in enumerate(stim_data) if stim == 1]\n",
    "    mild_indexes = [i for i, stim in enumerate(stim_data) if stim == 2]\n",
    "    hard_indexes = [i for i, stim in enumerate(stim_data) if stim == 3]\n",
    "    cold_indexes = [i for i, stim in enumerate(stim_data) if stim == 4]\n",
    "    room_indexes = [i for i, stim in enumerate(stim_data) if stim == 5]\n",
    "    warm_indexes = [i for i, stim in enumerate(stim_data) if stim == 6]\n",
    "\n",
    "    pinp_data_indexes = [round(float(time_stamps[i]) * sampling_rate) for i in pinp_indexes]\n",
    "    weak_data_indexes = [round(float(time_stamps[i]) * sampling_rate) for i in weak_indexes]\n",
    "    mild_data_indexes = [round(float(time_stamps[i]) * sampling_rate) for i in mild_indexes]\n",
    "    hard_data_indexes = [round(float(time_stamps[i]) * sampling_rate) for i in hard_indexes]\n",
    "    cold_data_indexes = [round(float(time_stamps[i]) * sampling_rate) for i in cold_indexes]\n",
    "    room_data_indexes = [round(float(time_stamps[i]) * sampling_rate) for i in room_indexes]\n",
    "    warm_data_indexes = [round(float(time_stamps[i]) * sampling_rate) for i in warm_indexes]\n",
    "\n",
    "\n",
    "    trace_duration = 5  # 5 seconds before and 30 seconds after each data index\n",
    "\n",
    "    # Convert trace duration from seconds to data points\n",
    "    trace_duration_points = trace_duration * sampling_rate\n",
    "\n",
    "    # Function to analyze and plot data for different index sets\n",
    "    def analyze_and_plot(indexes, dFF, sampling_rate, pre_start=5, post_start=10):\n",
    "        trace_data_matrix = []\n",
    "\n",
    "        for index in indexes:\n",
    "            start = int(index - pre_start * sampling_rate)\n",
    "            end = int(index + post_start * sampling_rate)\n",
    "            trace_data = dFF[start:end]\n",
    "            time = np.arange(start, end) / sampling_rate\n",
    "\n",
    "            # Calculate the baseline value\n",
    "            baseline_start = int(index - 5 * sampling_rate)\n",
    "            baseline_end = int(index - 3 * sampling_rate)\n",
    "            baseline = np.mean(dFF[baseline_start:baseline_end])\n",
    "\n",
    "            # Compute the relative trace data\n",
    "            relative_trace_data = trace_data - baseline\n",
    "\n",
    "            # Append relative_trace_data to the matrix\n",
    "            trace_data_matrix.append(relative_trace_data)\n",
    "\n",
    "\n",
    "        return np.array(trace_data_matrix)\n",
    "\n",
    "    # Example usage for each data index set\n",
    "    trace_data_matrix_pinp = analyze_and_plot(pinp_data_indexes, dFF, sampling_rate)\n",
    "    trace_data_matrix_weak = analyze_and_plot(weak_data_indexes, dFF, sampling_rate)\n",
    "    trace_data_matrix_mild = analyze_and_plot(mild_data_indexes, dFF, sampling_rate)\n",
    "    trace_data_matrix_hard = analyze_and_plot(hard_data_indexes, dFF, sampling_rate)\n",
    "    trace_data_matrix_cold = analyze_and_plot(cold_data_indexes, dFF, sampling_rate)\n",
    "    trace_data_matrix_room = analyze_and_plot(room_data_indexes, dFF, sampling_rate)\n",
    "    trace_data_matrix_warm = analyze_and_plot(warm_data_indexes, dFF, sampling_rate)\n",
    "\n",
    "    # Calculate the average traces for each index set\n",
    "    average_trace_pinp = np.mean(trace_data_matrix_pinp, axis=0)\n",
    "    average_trace_weak = np.mean(trace_data_matrix_weak, axis=0)\n",
    "    average_trace_mild = np.mean(trace_data_matrix_mild, axis=0)\n",
    "    average_trace_hard = np.mean(trace_data_matrix_hard, axis=0)\n",
    "    average_trace_cold = np.mean(trace_data_matrix_cold, axis=0)\n",
    "    average_trace_room = np.mean(trace_data_matrix_room, axis=0)\n",
    "    average_trace_warm = np.mean(trace_data_matrix_warm, axis=0)\n",
    "\n",
    "    traces = {\n",
    "        'average_trace_pinp': average_trace_pinp,\n",
    "        'average_trace_weak': average_trace_weak,\n",
    "        'average_trace_mild': average_trace_mild,\n",
    "        'average_trace_hard': average_trace_hard,\n",
    "        'average_trace_cold': average_trace_cold,\n",
    "        'average_trace_room': average_trace_room,\n",
    "        'average_trace_warm': average_trace_warm,\n",
    "    } \"\"\"\n",
    "\n",
    "    # Define the file path and name\n",
    "    #save_file_path = r'C:\\files\\data\\sensory_stim\\\\ + file_name + '.npy'\n",
    "\n",
    "    # Save the dictionary to a NumPy file\n",
    "    #np.save(save_file_path, traces)\n",
    "\n",
    "    vector = np.arange(index_on_new[0], index_on_new[0]+len(index_on_new)/2*60*sampling_rate, 30*sampling_rate)\n",
    "    #print(filename)\n",
    "    #print(np.round((index_on_new-vector)/sampling_rate))\n",
    "    gap = np.round((index_on_new-vector)/sampling_rate)\n",
    "\n",
    "    \"\"\"     y = uniform_filter1d(gap, size=5)\n",
    "    plt.plot(y)\n",
    "    plt.show()\n",
    "    plt.close() \"\"\"\n",
    "\n",
    "    # Define stimulus event mapping\n",
    "    stim_dict = {\n",
    "        0: \"0: Pinprick\",\n",
    "        1: \"1: 0.07g-Green\",\n",
    "        2: \"2: 0.4g-Dark blue\",\n",
    "        3: \"3: 2g-Purple\",\n",
    "        4: \"4: Cold water\",\n",
    "        5: \"5: Room temp\",\n",
    "        6: \"6: Hot water\"\n",
    "    }\n",
    "\n",
    "    # Stimuli sequence (as provided in your example), repeated twice because otherwise all excessive (past 126) stimuli are not saved\n",
    "    stim_sequence = [\n",
    "        0,0,0,4,4,4,5,5,5,1,1,1,3,3,3,2,2,2,6,6,6,\n",
    "        3,3,3,5,5,5,4,4,4,1,1,1,2,2,2,0,0,0,6,6,6,\n",
    "        6,6,6,4,4,4,5,5,5,0,0,0,3,3,3,1,1,1,2,2,2,\n",
    "        1,1,1,5,5,5,0,0,0,2,2,2,6,6,6,4,4,4,3,3,3,\n",
    "        0,0,0,5,5,5,6,6,6,3,3,3,1,1,1,4,4,4,2,2,2,\n",
    "        5,5,5,6,6,6,1,1,1,2,2,2,4,4,4,0,0,0,3,3,3,\n",
    "        0,0,0,4,4,4,5,5,5,1,1,1,3,3,3,2,2,2,6,6,6,\n",
    "        3,3,3,5,5,5,4,4,4,1,1,1,2,2,2,0,0,0,6,6,6,\n",
    "        6,6,6,4,4,4,5,5,5,0,0,0,3,3,3,1,1,1,2,2,2,\n",
    "        1,1,1,5,5,5,0,0,0,2,2,2,6,6,6,4,4,4,3,3,3,\n",
    "        0,0,0,5,5,5,6,6,6,3,3,3,1,1,1,4,4,4,2,2,2,\n",
    "        5,5,5,6,6,6,1,1,1,2,2,2,4,4,4,0,0,0,3,3,3,\n",
    "    ]\n",
    "\n",
    "    # Ensure index_on_new length matches stim_sequence\n",
    "    if len(index_on_new) != len(stim_sequence):\n",
    "        print(f\"Warning: {filename} has {len(index_on_new)} stimuli instead of expected {len(stim_sequence)}\")\n",
    "        \n",
    "        # Create DataFrame with available data\n",
    "        if len(index_on_new) < len(stim_sequence):\n",
    "            # If fewer stimuli than expected, use only available data\n",
    "            df = pd.DataFrame({\n",
    "                'Index': np.arange(1, len(index_on_new) + 1),\n",
    "                'Event': [stim_dict[stim] for stim in stim_sequence[:len(index_on_new)]],\n",
    "                'Frame': frame_on_new,\n",
    "                'Response': 1\n",
    "            })\n",
    "        else:\n",
    "            # If more stimuli than expected, truncate to expected length\n",
    "            df = pd.DataFrame({\n",
    "                'Index': np.arange(1, len(stim_sequence) + 1),\n",
    "                'Event': [stim_dict[stim] for stim in stim_sequence],\n",
    "                'Frame': frame_on_new[:len(stim_sequence)],\n",
    "                'Response': 1\n",
    "            })\n",
    "    else:\n",
    "        # Create DataFrame with all data when length matches\n",
    "        df = pd.DataFrame({\n",
    "            'Index': np.arange(1, len(stim_sequence) + 1),\n",
    "            'Event': [stim_dict[stim] for stim in stim_sequence],\n",
    "            'Frame': frame_on_new,\n",
    "            'Response': 1\n",
    "        })\n",
    "        \n",
    "        # Define the file path and name for the Excel file\n",
    "        excel_filename = f\"{filename}.xlsx\"\n",
    "        excel_file_path = os.path.join(os.path.dirname(ppd_file_path), excel_filename)\n",
    "\n",
    "        # Save the DataFrame as an Excel file\n",
    "        df.to_excel(excel_file_path, index=False)\n",
    "\n",
    "        print(f\"Excel file saved as {excel_file_path}\")\n",
    "        return\n",
    "\n",
    "    # Define the file path and name for the Excel file\n",
    "    excel_filename = f\"{filename}.xlsx\"\n",
    "    excel_file_path = os.path.join(os.path.dirname(ppd_file_path), excel_filename)\n",
    "\n",
    "    # Save the DataFrame as an Excel file\n",
    "    df.to_excel(excel_file_path, index=False)\n",
    "\n",
    "    print(f\"Excel file saved as {excel_file_path}\")\n",
    "\n",
    "    return time_on_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d8f7ff3-c138-4cdf-aded-b06a21b3dfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of PPD file paths\n",
    "ppd_file_paths = [\n",
    "    r'H:Magdalena/behavioral experiments/sensory stimulation/ACh_sensory/round_2/C426M1-2024-12-04-133620.ppd',\n",
    "    r'H:\\Magdalena\\behavioral experiments\\sensory stimulation\\ACh_sensory\\round_2\\C426M2-2024-12-05-145735.ppd',\n",
    "    r'H:\\Magdalena\\behavioral experiments\\sensory stimulation\\ACh_sensory\\round_2\\C426M3-2024-12-06-095120.ppd',\n",
    "    r'H:\\Magdalena\\behavioral experiments\\sensory stimulation\\ACh_sensory\\round_2\\C426M4-2024-12-06-113851.ppd',\n",
    "    r'H:\\Magdalena\\behavioral experiments\\sensory stimulation\\ACh_sensory\\round_2\\C427M1-2024-12-05-101315.ppd',\n",
    "    r'H:\\Magdalena\\behavioral experiments\\sensory stimulation\\ACh_sensory\\round_2\\C427M2-2024-12-04-111838.ppd',\n",
    "    r'H:\\Magdalena\\behavioral experiments\\sensory stimulation\\ACh_sensory\\round_2\\C427M3-2024-12-06-142127.ppd',\n",
    "    r'H:\\Magdalena\\behavioral experiments\\sensory stimulation\\ACh_sensory\\round_2\\C430M1-2024-12-06-161101.ppd',\n",
    "    r'H:\\Magdalena\\behavioral experiments\\sensory stimulation\\ACh_sensory\\round_2\\C430M3-2024-12-06-175236.ppd'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99b6a414-e0e3-4482-945d-fa9ef86a5c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_frame_values = [\n",
    "    4291,\n",
    "    2691,\n",
    "    1217,\n",
    "    1281,\n",
    "    2795,\n",
    "    3900,\n",
    "    1617,\n",
    "    1696,\n",
    "    1224\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "264a7b68-f952-4dd5-b3e7-a5ff84763eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: C426M1-2024-12-04-133620 has 163 stimuli instead of expected 252\n",
      "Excel file saved as H:Magdalena/behavioral experiments/sensory stimulation/ACh_sensory/round_2\\C426M1-2024-12-04-133620.xlsx\n",
      "Warning: C426M2-2024-12-05-145735 has 136 stimuli instead of expected 252\n",
      "Excel file saved as H:\\Magdalena\\behavioral experiments\\sensory stimulation\\ACh_sensory\\round_2\\C426M2-2024-12-05-145735.xlsx\n",
      "Warning: C426M3-2024-12-06-095120 has 158 stimuli instead of expected 252\n",
      "Excel file saved as H:\\Magdalena\\behavioral experiments\\sensory stimulation\\ACh_sensory\\round_2\\C426M3-2024-12-06-095120.xlsx\n",
      "Warning: C426M4-2024-12-06-113851 has 146 stimuli instead of expected 252\n",
      "Excel file saved as H:\\Magdalena\\behavioral experiments\\sensory stimulation\\ACh_sensory\\round_2\\C426M4-2024-12-06-113851.xlsx\n",
      "Warning: C427M1-2024-12-05-101315 has 140 stimuli instead of expected 252\n",
      "Excel file saved as H:\\Magdalena\\behavioral experiments\\sensory stimulation\\ACh_sensory\\round_2\\C427M1-2024-12-05-101315.xlsx\n",
      "Warning: C427M2-2024-12-04-111838 has 166 stimuli instead of expected 252\n",
      "Excel file saved as H:\\Magdalena\\behavioral experiments\\sensory stimulation\\ACh_sensory\\round_2\\C427M2-2024-12-04-111838.xlsx\n",
      "Warning: C427M3-2024-12-06-142127 has 135 stimuli instead of expected 252\n",
      "Excel file saved as H:\\Magdalena\\behavioral experiments\\sensory stimulation\\ACh_sensory\\round_2\\C427M3-2024-12-06-142127.xlsx\n",
      "Warning: C430M1-2024-12-06-161101 has 143 stimuli instead of expected 252\n",
      "Excel file saved as H:\\Magdalena\\behavioral experiments\\sensory stimulation\\ACh_sensory\\round_2\\C430M1-2024-12-06-161101.xlsx\n",
      "Warning: C430M3-2024-12-06-175236 has 141 stimuli instead of expected 252\n",
      "Excel file saved as H:\\Magdalena\\behavioral experiments\\sensory stimulation\\ACh_sensory\\round_2\\C430M3-2024-12-06-175236.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Process each PPD file\n",
    "for ppd_file, first_frame in zip(ppd_file_paths, first_frame_values):\n",
    "    process_ppd(ppd_file, first_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31776f9-1d80-4606-b5fa-b5ef3e3e04f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
